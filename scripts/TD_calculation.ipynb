{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from lightgbm.sklearn import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,auc,precision_recall_curve,average_precision_score,accuracy_score,f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def clf_select(name,pds=5):\n",
    "    if name =='DT':\n",
    "        clf = DecisionTreeClassifier(max_depth=100, min_samples_leaf=5, criterion='gini')\n",
    "    elif name =='DT_cv':\n",
    "        tree_para = {'max_depth': [50, 100, 200, 500, 1000]}\n",
    "        clf = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'SVM':\n",
    "        clf = SVC(kernel='linear', probability=True, C=1) #linear\n",
    "    elif name == 'SVM_cv':\n",
    "        tree_para = { 'C': [0.01, 0.1, 1, 10,100]}\n",
    "        clf = GridSearchCV(SVC(kernel= 'rbf',probability=True), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'RF':\n",
    "        clf = RandomForestClassifier(criterion='gini', max_depth=None, min_samples_split=2,n_estimators=1000)\n",
    "    elif name == 'RF_cv':\n",
    "        tree_para = {'n_estimators': [10, 50, 100, 200, 500], 'max_depth': [10, 50, 100, 200, 500]}\n",
    "        clf = GridSearchCV(RandomForestClassifier(), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'LR':\n",
    "        clf = LogisticRegression(penalty='l2',solver='liblinear',C=1)\n",
    "    elif name == 'LR_cv':\n",
    "        tree_para = {'C': [0.001, 0.1, 1, 10, 100]}\n",
    "        clf = GridSearchCV(LogisticRegression(penalty='l2',solver='liblinear'),tree_para, cv=pds, n_jobs=5,scoring='f1_macro')   \n",
    "    elif name == 'KNN':\n",
    "        clf = KNeighborsClassifier(n_neighbors=10, weights='distance', leaf_size=10)\n",
    "    elif name == 'KNN_cv':\n",
    "        tree_para = {'n_neighbors': [5, 10, 20, 50]}\n",
    "        clf = GridSearchCV(KNeighborsClassifier(weights='distance'), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'NN':\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(100), max_iter=200)\n",
    "    elif name == 'LGBoost':\n",
    "        clf = LGBMClassifier(num_leaves=5, n_estimators=100)\n",
    "    elif name == 'LGBoost_cv':\n",
    "        tree_para = {'max_depth': [5, 10, 50, 100, 500, 1000], 'n_estimators': [100, 500, 1000],\n",
    "                     'num_leaves': [20, 30, 50, 100]}\n",
    "        clf = GridSearchCV(LGBMClassifier(learning_rate=0.1), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'XGBoost':\n",
    "        clf = xgb.XGBClassifier(learning_rate=0.5, n_estimators=500, max_depth=50, min_child_weight=3,\n",
    "                                gamma=1,  # 惩罚项中叶子结点个数前的参数\n",
    "                                subsample=0.7,  # 随机选择80%样本建立决策树\n",
    "                                objective='binary:logistic',  # 指定损失函数\n",
    "                                nthread=5\n",
    "                                )\n",
    "    elif name == 'XGBoost_cv':\n",
    "        tree_para = {'max_depth': [10, 50, 100, 200, 500], 'n_estimators': [50, 100, 200, 500]}\n",
    "        clf = GridSearchCV(xgb.XGBClassifier(learning_rate=0.5, min_child_weight=3, gamma=3, subsample=0.7,\n",
    "                                             objective='binary:logistic',\n",
    "                                             scale_pos_weight=1, nthread=5), tree_para, cv=pds, n_jobs=5,scoring='f1_macro')\n",
    "    \n",
    "    elif name == 'ENSEMBLE_hard':\n",
    "        clf = VotingClassifier(estimators=[('RF',RandomForestClassifier(criterion='gini', max_depth=None, min_samples_split=2,n_estimators=1000)),\n",
    "                                           ('SVM',SVC(kernel='linear', probability=True, C=0.8)),\n",
    "                                           ('LR',LogisticRegression(penalty='l2',solver='liblinear')),\n",
    "                                           ('DT',DecisionTreeClassifier(max_depth=100, min_samples_leaf=5, criterion='gini'))],voting = 'hard')\n",
    "    elif name == 'ENSEMBLE_soft':\n",
    "        clf = VotingClassifier(estimators=[('RF',RandomForestClassifier(criterion='gini', max_depth=None, min_samples_split=2,n_estimators=1000)),\n",
    "                                           ('LR',LogisticRegression(penalty='l2',solver='liblinear'))],voting = 'soft')\n",
    "#     ('SVM',SVC(kernel='linear', probability=True, C=0.8)),\n",
    "#     ('DT',DecisionTreeClassifier(max_depth=100, min_samples_leaf=5, criterion='gini'))\n",
    "    return clf\n",
    "\n",
    "def clf_select_multi(name, pds=5):\n",
    "    if name == 'DT':\n",
    "        clf = DecisionTreeClassifier(max_depth=100, min_samples_leaf=5, criterion='gini')\n",
    "    elif name == 'DT_cv':\n",
    "        tree_para = {'max_depth': [50, 100, 200, 500, 1000]}\n",
    "        clf = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'SVM':\n",
    "        clf = SVC(kernel='rbf', probability=True, C=1)\n",
    "    elif name == 'SVM_cv':\n",
    "        tree_para = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "        clf = GridSearchCV(SVC(kernel='rbf', probability=True), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'RF':\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth=100)\n",
    "    elif name == 'RF_cv':\n",
    "        tree_para = {'n_estimators': [10, 50, 100, 200, 500], 'max_depth': [10, 50, 100, 200, 500]}\n",
    "        clf = GridSearchCV(RandomForestClassifier(), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'LR':\n",
    "        clf = LogisticRegression(penalty='l2', solver='liblinear', C=1)\n",
    "    elif name == 'LR_cv':\n",
    "        tree_para = {'C': [0.001, 0.1, 1, 10, 100]}\n",
    "        clf = GridSearchCV(LogisticRegression(penalty='l2', solver='liblinear'), tree_para, cv=pds, n_jobs=5,scoring='f1_macro')\n",
    "    elif name == 'KNN':\n",
    "        clf = KNeighborsClassifier(n_neighbors=10)\n",
    "    elif name == 'KNN_cv':\n",
    "        tree_para = {'n_neighbors': [5, 10, 20, 50]}\n",
    "        clf = GridSearchCV(KNeighborsClassifier(weights='distance'), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'NN':\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(100), max_iter=200)\n",
    "    elif name == 'LGBoost':\n",
    "        clf = LGBMClassifier(num_leaves=5, n_estimators=100)\n",
    "    elif name == 'LGBoost_cv':\n",
    "        tree_para = {'max_depth': [5, 10, 50, 100, 500, 1000], 'n_estimators': [100, 500, 1000],\n",
    "                     'num_leaves': [20, 30, 50, 100]}\n",
    "        clf = GridSearchCV(LGBMClassifier(learning_rate=0.1), tree_para, cv=pds, n_jobs=5, scoring='f1_macro')\n",
    "    elif name == 'XGBoost':\n",
    "        clf = xgb.XGBClassifier(learning_rate=0.5, n_estimators=500, max_depth=50, min_child_weight=3,\n",
    "                                gamma=1,  # 惩罚项中叶子结点个数前的参数\n",
    "                                subsample=0.7,  # 随机选择80%样本建立决策树\n",
    "                                objective='multi:softprob',  # 指定损失函数\n",
    "                                nthread=5\n",
    "                                )\n",
    "    elif name == 'XGBoost_cv':\n",
    "        tree_para = {'max_depth': [10, 50, 100, 200, 500], 'n_estimators': [50, 100, 200, 500]}\n",
    "        clf = GridSearchCV(xgb.XGBClassifier(learning_rate=0.5, min_child_weight=3, gamma=3, subsample=0.7,\n",
    "                                             objective='binary:logistic',\n",
    "                                             scale_pos_weight=1, nthread=5), tree_para, cv=pds,n_jobs=5, scoring='f1_macro')\n",
    "    return clf\n",
    "\n",
    "def plot_AUROC(Y_test,Y_prob,F):\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test,Y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('AUROC:',roc_auc)\n",
    "    # plot ROC curve\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(fpr, tpr, '-', color='blue', label='RandomForest AUC = {:.4f}'.format(roc_auc), lw=2)\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random Chance')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.title('ROC curve of ' + F)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.legend(loc='best',fontsize='small')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('./figure/cellline/' + F + '_AUROC.png',dpi=600)\n",
    "    #plt.savefig('figure/LR_small_9.png',dpi=600)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_AUPRC(Y_test,Y_prob,F):\n",
    "    precision, recall, thresholds = precision_recall_curve(Y_test,Y_prob)\n",
    "    aupr = auc(recall,precision)\n",
    "    print('AUPRC:',aupr)\n",
    "    # plot ROC curve\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(recall,precision, '-', color='blue', label='RandomForest AUPRC = {:.4f}'.format(aupr), lw=2)\n",
    "    plt.plot([0, 1], [1, 0], '--', color=(0.6, 0.6, 0.6), label='Random Chance')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.title('AUPRC curve of ' + F)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(loc='best',fontsize='small')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('./figure/cellline/' + F + '_AUPRC.png',dpi=600)\n",
    "    #plt.savefig('figure/LR_small_9.png',dpi=600)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def find_metrics_best_for_shuffle(label, prob, cut_spe=0.95):\n",
    "    fpr, tpr, _ = roc_curve(label, prob)\n",
    "    a = 1 - fpr\n",
    "    b = tpr\n",
    "    Sensitivity = b\n",
    "    Specificity = a\n",
    "    Sensitivity_ = Sensitivity[Specificity >= cut_spe]\n",
    "    if (len(Sensitivity_) == 1) & (Sensitivity_[0] == 0):\n",
    "        Sensitivity_best = ((Sensitivity[1] - Sensitivity[0]) / (Specificity[1] - Specificity[0])) * cut_spe + Sensitivity[1] - ((Sensitivity[1] - Sensitivity[0]) / (Specificity[1] - Specificity[0])) * \\\n",
    "                           Specificity[1]\n",
    "    else:\n",
    "        Sensitivity_best = np.max(Sensitivity_)\n",
    "\n",
    "    return Sensitivity_best, Sensitivity, Specificity\n",
    "\n",
    "\n",
    "def plot_roc_multi(prob, label):\n",
    "    pre_label = prob.argmax(axis=1)\n",
    "    acc = accuracy_score(label, pre_label)\n",
    "    auc_macro_ovr = roc_auc_score(label, prob, average='macro', multi_class='ovr')\n",
    "    auc_macro_ovo = roc_auc_score(label, prob, average='macro', multi_class='ovo')\n",
    "    auc_weighted_ovr = roc_auc_score(label, prob, average='weighted', multi_class='ovr')\n",
    "    auc_weighted_ovo = roc_auc_score(label, prob, average='weighted', multi_class='ovo')\n",
    "    f1_macro = f1_score(label, pre_label, average='macro')\n",
    "    f1_weighted = f1_score(label, pre_label, average='weighted')\n",
    "    return acc, auc_weighted_ovr, auc_weighted_ovo, auc_macro_ovr, auc_macro_ovo, f1_weighted, f1_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1174 2361\n",
      "191 702\n",
      "241 473\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "method_dict = {}\n",
    "DeltaG = {'AA': -0.93, 'UU': -0.93, 'AU': -1.10, 'UA': -1.33, 'CU': -2.08, 'AG': -2.08, 'CA': -2.11, 'UG': -2.11, 'GU': -2.24,  'AC': -2.24, 'GA': -2.35,  'UC': -2.35, 'CG': -2.36, 'GG': -3.26, 'CC': -3.26, 'GC': -3.42, 'init': 4.09, 'endAU': 0.45, 'sym': 0.43}\n",
    "DeltaH = {'AA': -6.82, 'UU': -6.82, 'AU': -9.38, 'UA': -7.69, 'CU': -10.48, 'AG': -10.48, 'CA': -10.44, 'UG': -10.44, 'GU': -11.40,  'AC': -11.40, 'GA': -12.44,  'UC': -12.44, 'CG': -10.64, 'GG': -13.39, 'CC': -13.39, 'GC': -14.88, 'init': 3.61, 'endAU': 3.72, 'sym': 0}\n",
    "\n",
    "def antiRNA(RNA):\n",
    "    antiRNA = []\n",
    "    for i in RNA:\n",
    "        if i == 'A' or i == 'a':\n",
    "            antiRNA.append('T')\n",
    "        elif i == 'U' or i == 'u' or i == 'T' or i == 't':\n",
    "            antiRNA.append('A')\n",
    "        elif i == 'C' or i == 'c':\n",
    "            antiRNA.append('G')\n",
    "        elif i == 'G' or i == 'g':\n",
    "            antiRNA.append('C')\n",
    "    return ''.join(antiRNA[::-1])\n",
    "\n",
    "def Calculate_DGH(seq):\n",
    "    DG_all = 0\n",
    "    DG_all += DeltaG['init']\n",
    "    DG_all += ((seq[0] + seq[len(seq)-1]).count('A') + (seq[0] + seq[len(seq)-1]).count('U')) * DeltaG['endAU']\n",
    "    DG_all += DeltaG['sym'] if antiRNA(seq).replace('T','U') == seq else 0\n",
    "    for i in range(len(seq) - 1):\n",
    "        DG_all += DeltaG[seq[i] + seq[i+1]]\n",
    "    DH_all = 0\n",
    "    DH_all += DeltaH['init']\n",
    "    DH_all += ((seq[0] + seq[len(seq)-1]).count('A') + (seq[0] + seq[len(seq)-1]).count('U')) * DeltaH['endAU']\n",
    "    DH_all += DeltaH['sym'] if antiRNA(seq).replace('T','U') == seq else 0\n",
    "    for i in range(len(seq) - 1):\n",
    "        DH_all += DeltaH[seq[i] + seq[i+1]]\n",
    "    return DG_all,DH_all\n",
    "\n",
    "def Calculate_end_diff(siRNA):\n",
    "    count = 0\n",
    "    _5 = siRNA[:2] # 5'end\n",
    "    _3 = siRNA[-2:] # 3' end\n",
    "    if _5 in ['AC','AG','UC','UG']:\n",
    "        count += 1\n",
    "    elif _5 in ['GA','GU','CA','CU']:\n",
    "        count -= 1\n",
    "    if _3 in ['AC','AG','UC','UG']:\n",
    "        count += 1\n",
    "    elif _3 in ['GA','GU','CA','CU']:\n",
    "        count -= 1\n",
    "    \n",
    "    return float('{:.2f}'.format(DeltaG[_5] - DeltaG[_3] + count * 0.45))\n",
    "    \n",
    "Hu = pd.read_csv(\"./data/Hu.csv\")\n",
    "Taka = pd.read_csv(\"./data/Taka.csv\")\n",
    "new = pd.read_csv(\"./data/new.csv\")\n",
    "print(sum(Hu['label'] >= (0.7 / 1.341)),Hu.shape[0])\n",
    "print(sum(Taka['label'] >= 0.7),Taka.shape[0])\n",
    "print(sum(new['label'] >= 0.7),new.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 23 thermodynamic params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n"
     ]
    }
   ],
   "source": [
    "HuTD = Hu\n",
    "# HuTD['targetStruct'] = HuTD['siRNA']\n",
    "# HuTD['intraOligo'] = HuTD['siRNA']\n",
    "# HuTD['interOligo'] = HuTD['siRNA']\n",
    "# HuTD['duplex'] = HuTD['siRNA']\n",
    "HuTD['ends'] = HuTD['siRNA']\n",
    "HuTD['DG_1'] = HuTD['siRNA']\n",
    "HuTD['DH_1'] = HuTD['siRNA']\n",
    "HuTD['U_1'] = HuTD['siRNA']\n",
    "HuTD['G_1'] = HuTD['siRNA']\n",
    "HuTD['DH_all'] = HuTD['siRNA']\n",
    "HuTD['U_all'] = HuTD['siRNA']\n",
    "HuTD['UU_1'] = HuTD['siRNA']\n",
    "HuTD['G_all'] = HuTD['siRNA']\n",
    "HuTD['GG_1'] = HuTD['siRNA']\n",
    "HuTD['GC_1'] = HuTD['siRNA']\n",
    "HuTD['GG_all'] = HuTD['siRNA']\n",
    "HuTD['DG_2'] = HuTD['siRNA']\n",
    "HuTD['UA_all'] = HuTD['siRNA']\n",
    "HuTD['U_2'] = HuTD['siRNA']\n",
    "HuTD['C_1'] = HuTD['siRNA']\n",
    "HuTD['CC_all'] = HuTD['siRNA']\n",
    "HuTD['DG_18'] = HuTD['siRNA']\n",
    "HuTD['CC_1'] = HuTD['siRNA']\n",
    "HuTD['GC_all'] = HuTD['siRNA']\n",
    "HuTD['CG_1'] = HuTD['siRNA']\n",
    "HuTD['DG_13'] = HuTD['siRNA']\n",
    "HuTD['UU_all'] = HuTD['siRNA']\n",
    "HuTD['A_19'] = HuTD['siRNA']\n",
    "\n",
    "for i in range(HuTD.shape[0]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    HuTD['ends'] = [Calculate_end_diff(i) for i in HuTD['siRNA']]\n",
    "    HuTD['DG_1'][i] = DeltaG[HuTD.iloc[i,0][0:2]]\n",
    "    HuTD['DH_1'][i] = DeltaH[HuTD.iloc[i,0][0:2]]\n",
    "    HuTD['U_1'][i] = int(HuTD.iloc[i,0][0] == 'U')\n",
    "    HuTD['G_1'][i] = int(HuTD.iloc[i,0][0] == 'G')\n",
    "    HuTD['DH_all'][i] = Calculate_DGH(HuTD.iloc[i,0])[1]\n",
    "    HuTD['U_all'][i] = HuTD.iloc[i,0].count('U') / 19\n",
    "    HuTD['UU_1'][i] = int(HuTD.iloc[i,0][0:2] == 'UU')\n",
    "    HuTD['G_all'][i] = HuTD.iloc[i,0].count('G') / 19\n",
    "    HuTD['GG_1'][i] = int(HuTD.iloc[i,0][0:2] == 'GG')\n",
    "    HuTD['GC_1'][i] = int(HuTD.iloc[i,0][0:2] == 'GC')\n",
    "    HuTD['GG_all'][i] = [HuTD.iloc[i,0][j]+HuTD.iloc[i,0][j+1] for j in range(18)].count('GG') / 18\n",
    "    HuTD['DG_2'][i] = DeltaG[HuTD.iloc[i,0][1:3]]\n",
    "    HuTD['UA_all'][i] = [HuTD.iloc[i,0][j]+HuTD.iloc[i,0][j+1] for j in range(18)].count('UA') / 18\n",
    "    HuTD['U_2'][i] = int(HuTD.iloc[i,0][1] == 'U')\n",
    "    HuTD['C_1'][i] = int(HuTD.iloc[i,0][0] == 'C')\n",
    "    HuTD['CC_all'][i] = [HuTD.iloc[i,0][j]+HuTD.iloc[i,0][j+1] for j in range(18)].count('CC') / 18\n",
    "    HuTD['DG_18'][i] = DeltaG[HuTD.iloc[i,0][17:19]]\n",
    "    HuTD['CC_1'][i] = int(HuTD.iloc[i,0][0:2] == 'CC')\n",
    "    HuTD['GC_all'][i] = [HuTD.iloc[i,0][j]+HuTD.iloc[i,0][j+1] for j in range(18)].count('GC') / 18\n",
    "    HuTD['CG_1'][i] = int(HuTD.iloc[i,0][0:2] == 'CG')\n",
    "    HuTD['DG_13'][i] = DeltaG[HuTD.iloc[i,0][12:14]]\n",
    "    HuTD['UU_all'][i] = [HuTD.iloc[i,0][j]+HuTD.iloc[i,0][j+1] for j in range(18)].count('UU') / 18\n",
    "    HuTD['A_19'][i] = int(HuTD.iloc[i,0][18] == 'A')\n",
    "\n",
    "HuTD.to_csv('data/HuTD.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "TakaTD = Taka\n",
    "TakaTD['ends'] = TakaTD['siRNA']\n",
    "TakaTD['DG_1'] = TakaTD['siRNA']\n",
    "TakaTD['DH_1'] = TakaTD['siRNA']\n",
    "TakaTD['U_1'] = TakaTD['siRNA']\n",
    "TakaTD['G_1'] = TakaTD['siRNA']\n",
    "TakaTD['DH_all'] = TakaTD['siRNA']\n",
    "TakaTD['U_all'] = TakaTD['siRNA']\n",
    "TakaTD['UU_1'] = TakaTD['siRNA']\n",
    "TakaTD['G_all'] = TakaTD['siRNA']\n",
    "TakaTD['GG_1'] = TakaTD['siRNA']\n",
    "TakaTD['GC_1'] = TakaTD['siRNA']\n",
    "TakaTD['GG_all'] = TakaTD['siRNA']\n",
    "TakaTD['DG_2'] = TakaTD['siRNA']\n",
    "TakaTD['UA_all'] = TakaTD['siRNA']\n",
    "TakaTD['U_2'] = TakaTD['siRNA']\n",
    "TakaTD['C_1'] = TakaTD['siRNA']\n",
    "TakaTD['CC_all'] = TakaTD['siRNA']\n",
    "TakaTD['DG_18'] = TakaTD['siRNA']\n",
    "TakaTD['CC_1'] = TakaTD['siRNA']\n",
    "TakaTD['GC_all'] = TakaTD['siRNA']\n",
    "TakaTD['CG_1'] = TakaTD['siRNA']\n",
    "TakaTD['DG_13'] = TakaTD['siRNA']\n",
    "TakaTD['UU_all'] = TakaTD['siRNA']\n",
    "TakaTD['A_19'] = TakaTD['siRNA']\n",
    "\n",
    "for i in range(TakaTD.shape[0]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    TakaTD['ends'] = [Calculate_end_diff(i) for i in TakaTD['siRNA']]\n",
    "    TakaTD['DG_1'][i] = DeltaG[TakaTD.iloc[i,0][0:2]]\n",
    "    TakaTD['DH_1'][i] = DeltaH[TakaTD.iloc[i,0][0:2]]\n",
    "    TakaTD['U_1'][i] = int(TakaTD.iloc[i,0][0] == 'U')\n",
    "    TakaTD['G_1'][i] = int(TakaTD.iloc[i,0][0] == 'G')\n",
    "    TakaTD['DH_all'][i] = Calculate_DGH(TakaTD.iloc[i,0])[1]\n",
    "    TakaTD['U_all'][i] = TakaTD.iloc[i,0].count('U') / 19\n",
    "    TakaTD['UU_1'][i] = int(TakaTD.iloc[i,0][0:2] == 'UU')\n",
    "    TakaTD['G_all'][i] = TakaTD.iloc[i,0].count('G') / 19\n",
    "    TakaTD['GG_1'][i] = int(TakaTD.iloc[i,0][0:2] == 'GG')\n",
    "    TakaTD['GC_1'][i] = int(TakaTD.iloc[i,0][0:2] == 'GC')\n",
    "    TakaTD['GG_all'][i] = [TakaTD.iloc[i,0][j]+TakaTD.iloc[i,0][j+1] for j in range(18)].count('GG') / 18\n",
    "    TakaTD['DG_2'][i] = DeltaG[TakaTD.iloc[i,0][1:3]]\n",
    "    TakaTD['UA_all'][i] = [TakaTD.iloc[i,0][j]+TakaTD.iloc[i,0][j+1] for j in range(18)].count('UA') / 18\n",
    "    TakaTD['U_2'][i] = int(TakaTD.iloc[i,0][1] == 'U')\n",
    "    TakaTD['C_1'][i] = int(TakaTD.iloc[i,0][0] == 'C')\n",
    "    TakaTD['CC_all'][i] = [TakaTD.iloc[i,0][j]+TakaTD.iloc[i,0][j+1] for j in range(18)].count('CC') / 18\n",
    "    TakaTD['DG_18'][i] = DeltaG[TakaTD.iloc[i,0][17:19]]\n",
    "    TakaTD['CC_1'][i] = int(TakaTD.iloc[i,0][0:2] == 'CC')\n",
    "    TakaTD['GC_all'][i] = [TakaTD.iloc[i,0][j]+TakaTD.iloc[i,0][j+1] for j in range(18)].count('GC') / 18\n",
    "    TakaTD['CG_1'][i] = int(TakaTD.iloc[i,0][0:2] == 'CG')\n",
    "    TakaTD['DG_13'][i] = DeltaG[TakaTD.iloc[i,0][12:14]]\n",
    "    TakaTD['UU_all'][i] = [TakaTD.iloc[i,0][j]+TakaTD.iloc[i,0][j+1] for j in range(18)].count('UU') / 18\n",
    "    TakaTD['A_19'][i] = int(TakaTD.iloc[i,0][18] == 'A')\n",
    "\n",
    "TakaTD.to_csv('data/TakaTD.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "newTD = new\n",
    "# newTD['targetStruct'] = newTD['siRNA']\n",
    "# newTD['intraOligo'] = newTD['siRNA']\n",
    "# newTD['interOligo'] = newTD['siRNA']\n",
    "# newTD['duplex'] = newTD['siRNA']\n",
    "newTD['ends'] = newTD['siRNA']\n",
    "newTD['DG_1'] = newTD['siRNA']\n",
    "newTD['DH_1'] = newTD['siRNA']\n",
    "newTD['U_1'] = newTD['siRNA']\n",
    "newTD['G_1'] = newTD['siRNA']\n",
    "newTD['DH_all'] = newTD['siRNA']\n",
    "newTD['U_all'] = newTD['siRNA']\n",
    "newTD['UU_1'] = newTD['siRNA']\n",
    "newTD['G_all'] = newTD['siRNA']\n",
    "newTD['GG_1'] = newTD['siRNA']\n",
    "newTD['GC_1'] = newTD['siRNA']\n",
    "newTD['GG_all'] = newTD['siRNA']\n",
    "newTD['DG_2'] = newTD['siRNA']\n",
    "newTD['UA_all'] = newTD['siRNA']\n",
    "newTD['U_2'] = newTD['siRNA']\n",
    "newTD['C_1'] = newTD['siRNA']\n",
    "newTD['CC_all'] = newTD['siRNA']\n",
    "newTD['DG_18'] = newTD['siRNA']\n",
    "newTD['CC_1'] = newTD['siRNA']\n",
    "newTD['GC_all'] = newTD['siRNA']\n",
    "newTD['CG_1'] = newTD['siRNA']\n",
    "newTD['DG_13'] = newTD['siRNA']\n",
    "newTD['UU_all'] = newTD['siRNA']\n",
    "newTD['A_19'] = newTD['siRNA']\n",
    "\n",
    "for i in range(newTD.shape[0]):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    newTD['ends'] = [Calculate_end_diff(i) for i in newTD['siRNA']]\n",
    "    newTD['DG_1'][i] = DeltaG[newTD.iloc[i,0][0:2]]\n",
    "    newTD['DH_1'][i] = DeltaH[newTD.iloc[i,0][0:2]]\n",
    "    newTD['U_1'][i] = int(newTD.iloc[i,0][0] == 'U')\n",
    "    newTD['G_1'][i] = int(newTD.iloc[i,0][0] == 'G')\n",
    "    newTD['DH_all'][i] = Calculate_DGH(newTD.iloc[i,0])[1]\n",
    "    newTD['U_all'][i] = newTD.iloc[i,0].count('U') / 19\n",
    "    newTD['UU_1'][i] = int(newTD.iloc[i,0][0:2] == 'UU')\n",
    "    newTD['G_all'][i] = newTD.iloc[i,0].count('G') / 19\n",
    "    newTD['GG_1'][i] = int(newTD.iloc[i,0][0:2] == 'GG')\n",
    "    newTD['GC_1'][i] = int(newTD.iloc[i,0][0:2] == 'GC')\n",
    "    newTD['GG_all'][i] = [newTD.iloc[i,0][j]+newTD.iloc[i,0][j+1] for j in range(18)].count('GG') / 18\n",
    "    newTD['DG_2'][i] = DeltaG[newTD.iloc[i,0][1:3]]\n",
    "    newTD['UA_all'][i] = [newTD.iloc[i,0][j]+newTD.iloc[i,0][j+1] for j in range(18)].count('UA') / 18\n",
    "    newTD['U_2'][i] = int(newTD.iloc[i,0][1] == 'U')\n",
    "    newTD['C_1'][i] = int(newTD.iloc[i,0][0] == 'C')\n",
    "    newTD['CC_all'][i] = [newTD.iloc[i,0][j]+newTD.iloc[i,0][j+1] for j in range(18)].count('CC') / 18\n",
    "    newTD['DG_18'][i] = DeltaG[newTD.iloc[i,0][17:19]]\n",
    "    newTD['CC_1'][i] = int(newTD.iloc[i,0][0:2] == 'CC')\n",
    "    newTD['GC_all'][i] = [newTD.iloc[i,0][j]+newTD.iloc[i,0][j+1] for j in range(18)].count('GC') / 18\n",
    "    newTD['CG_1'][i] = int(newTD.iloc[i,0][0:2] == 'CG')\n",
    "    newTD['DG_13'][i] = DeltaG[newTD.iloc[i,0][12:14]]\n",
    "    newTD['UU_all'][i] = [newTD.iloc[i,0][j]+newTD.iloc[i,0][j+1] for j in range(18)].count('UU') / 18\n",
    "    newTD['A_19'][i] = int(newTD.iloc[i,0][18] == 'A')\n",
    "\n",
    "newTD.to_csv('data/newTD.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
